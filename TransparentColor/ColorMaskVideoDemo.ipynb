{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b2647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9378379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(\"C:/Users/Jimmy/Documents/Experimental_Forest/IMG_1258-720p.mp4\")\n",
    "total_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "df = pd.read_csv('GT_IMG_1258.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(startX, startY, endX, endY):\n",
    "    YPoints = []\n",
    "    XPoints = []\n",
    "    dx = endX - startX\n",
    "    dy = endY - startY\n",
    "    steps = abs(dx) if (abs(dx) > abs(dy)) else abs(dy)\n",
    "    Xinc = dx / steps\n",
    "    Yinc = dy / steps\n",
    "    X = startX\n",
    "    Y = startY\n",
    "    for i in range(int(steps)):\n",
    "        XPoints.append(round(X))\n",
    "        YPoints.append(round(Y))\n",
    "        X += Xinc\n",
    "        Y += Yinc\n",
    "    return XPoints, YPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a00a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillROI(GT_df, frame_index):\n",
    "    \n",
    "    max_width = 375\n",
    "    max_y = 720 # represents floor in front\n",
    "    min_y = 230 # represents \"horizon\"\n",
    "    slope = max_width / (max_y-min_y)\n",
    "    point_count = GT_df[\"#ofPoints\"][frame_index]\n",
    "    frame_points = GT_df.iloc[frame_index, 2:(2+point_count*2)]\n",
    "    Xlist = []\n",
    "    Ylist = []\n",
    "    Xpoints = []\n",
    "    Ypoints = []\n",
    "    \n",
    "    for i in range(0, point_count*2-2, 2):\n",
    "        # OpenCV implementation of the line for comparison\n",
    "#         cv2.line(frame, (int(frame_points[i]), int(frame_points[i+1])), \n",
    "#                          (int(frame_points[i+2]), int(frame_points[i+3])), (0,0,255), 2) \n",
    "        \n",
    "        Xpoints, Ypoints = drawLine(int(frame_points[i]), int(frame_points[i+1]), \n",
    "                                     int(frame_points[i+2]), int(frame_points[i+3]))\n",
    "        \n",
    "        # This section determines which pixels are part of the ROI (region of interest) from the labeled points\n",
    "        for j in range(len(Xpoints)):\n",
    "            # This linear equation serves as a base\n",
    "            width = max_width - (max_y-Ypoints[j]) * slope\n",
    "            width = int(width//2)\n",
    "            Xlist.append(Xpoints[j])\n",
    "            Ylist.append(Ypoints[j])\n",
    "            for k in range(1, width, 1):\n",
    "                Xlist.append(Xpoints[j]+k)\n",
    "                Ylist.append(Ypoints[j])\n",
    "                Xlist.append(Xpoints[j]-k)\n",
    "                Ylist.append(Ypoints[j])\n",
    "                             \n",
    "#         Xlist += Xpoints\n",
    "#         Ylist += Ypoints\n",
    "    return Xlist, Ylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bb69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyMask(frame, Xlist, Ylist):\n",
    "    mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    # Define the coordinates of the region of interest (roi_corners)\n",
    "    roi_corners = np.array([(x, y) for x, y in zip(Xlist, Ylist)], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [roi_corners], (255, 255, 255))\n",
    "\n",
    "    # Darken the shade of the mask color (light green)\n",
    "    dark_green = (0, 175, 0)\n",
    "    darkened_mask = cv2.bitwise_and(mask, mask, mask=mask)\n",
    "\n",
    "    # Create an overlay with the same size as the image\n",
    "    overlay = np.zeros_like(frame)\n",
    "    overlay[darkened_mask != 0] = dark_green\n",
    "\n",
    "    masked_overlay = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "\n",
    "    output = cv2.addWeighted(frame, 1, masked_overlay, 0.25, 0.5)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cc485d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m Xlist, Ylist \u001b[38;5;241m=\u001b[39m fillROI(df, frame_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m masked_frame \u001b[38;5;241m=\u001b[39m \u001b[43mapplyMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYlist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m'\u001b[39m, masked_frame)\n\u001b[0;32m     13\u001b[0m frame_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fast_forward\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mapplyMask\u001b[1;34m(frame, Xlist, Ylist)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapplyMask\u001b[39m(frame, Xlist, Ylist):\n\u001b[1;32m----> 2\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Define the coordinates of the region of interest (roi_corners)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     roi_corners \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(x, y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(Xlist, Ylist)], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "frame_index = -1\n",
    "fast_forward = 1\n",
    "counter = 0\n",
    "capture = cv2.VideoCapture(\"C:/Users/Jimmy/Documents/Experimental_Forest/IMG_1258-720p.mp4\")\n",
    "while True:\n",
    "    capture.set(cv2.CAP_PROP_FRAME_COUNT, frame_index)\n",
    "    isTrue, frame = capture.read()\n",
    "    if (frame_index < total_frames-1) & ((counter%fast_forward)==0):\n",
    "        counter = 0\n",
    "        Xlist, Ylist = fillROI(df, frame_index+1)\n",
    "        masked_frame = applyMask(frame, Xlist, Ylist)\n",
    "        cv2.imshow('Video', masked_frame)\n",
    "        frame_index += fast_forward\n",
    "        if cv2.waitKey(2) & 0xFF==ord('d'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if cv2.waitKey(2) & 0xFF==ord('f'):\n",
    "            if fast_forward == 1:\n",
    "                fast_forward = 5\n",
    "            else:\n",
    "                fast_forward = 1\n",
    "    counter+=1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fabd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
